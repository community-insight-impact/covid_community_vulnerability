{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating merged dataset...\n"
     ]
    }
   ],
   "source": [
    "PRINTING = 1\n",
    "if PRINTING:\n",
    "    print('Creating merged dataset...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging County Health Rankings...\n",
      "(3193, 76)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# County Health Rankings #\n",
    "##########################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging County Health Rankings...')\n",
    "\n",
    "# Load Ranked Measure Data\n",
    "cols_1 = [0, 1, 2, 3, 4, 23, 27, 31, 36, 55, 59, 63, 65, 69, 71, 77, 82, 84, 104, 109, 113, 127, 134, 142, 146, 152, 154, 165, 169, 174, 177, 180, 199, 201, 203, 216, 236]\n",
    "c1_data = pd.read_excel('../data/2020_CHRD.xlsx', sheet_name='Ranked Measure Data', header=1, usecols=cols_1)\n",
    "c1_data = c1_data.drop(columns='% Uninsured')\n",
    "\n",
    "# Load Additional Measure Data\n",
    "cols_2 = [0, 3, 22, 41, 60, 787, 81, 84, 88, 90, 92, 94, 113, 131, 135, 139, 143, 144, 147, 152, 157, 175,\n",
    "          176, 177, 178, 197, 217, 238, 241, 245, 248, 249, 250, 252, 254, 256, 258, 260, 262, 264, 267, 269]\n",
    "c2_data = pd.read_excel('../data/2020_CHRD.xlsx', sheet_name='Additional Measure Data', header=1, usecols=cols_2)\n",
    "\n",
    "# Clean\n",
    "c2_data = c2_data.rename(columns={'% Uninsured.1': '% Children Uninsured', 'Segregation index':\n",
    "                                  'Black/White Segregation Index', 'Segregation Index':\n",
    "                                  'non-White/White Segregation Index', 'Average Grade Performance':\n",
    "                                  'Average Reading Performance', 'Average Grade Performance.1': 'Average Math Performance',\n",
    "                                  })\n",
    "\n",
    "# Merge c1 and c2\n",
    "merged_data = pd.merge(c1_data, c2_data, on='FIPS')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging internet_percent...\n",
      "(3140, 82)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Internet Data #\n",
    "#################\n",
    "# Note: Some counties with low numbers have -9999 to 'preserve confidentiality' so we need to interpolate\n",
    "# Note: Some counties have a ratio above one, presumably because some houses have multiple connections\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging internet_percent...')\n",
    "\n",
    "# Load\n",
    "internet_data = pd.read_excel('../data/internet_data.xlsx', sheet_name='County Connections Dec 2017', usecols=[0, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Clean\n",
    "internet_data = internet_data.replace(-9999, np.nan)  # Fill in missing data with mean value\n",
    "i_mean = internet_data['ratio'].mean()\n",
    "internet_data = internet_data.fillna(0.698)\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, internet_data, left_on='FIPS', right_on='countycode')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging COVID data...\n",
      "Merging NYC COVID data...\n",
      "(3130, 88)\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# COVID County Data #\n",
    "#####################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging COVID data...')\n",
    "\n",
    "# Load\n",
    "covid_data = pd.read_csv('../../nyt_data/us-counties.csv')\n",
    "\n",
    "# Clean\n",
    "last_day = covid_data['date'].iloc[-1]\n",
    "covid_data = covid_data.loc[covid_data.date == last_day]\n",
    "covid_data['fips'] = covid_data['fips'].fillna(0).astype(int)\n",
    "covid_data['fips'] = covid_data['fips'].astype(int)\n",
    "\n",
    "\n",
    "############\n",
    "# NYC Data #\n",
    "############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging NYC COVID data...')\n",
    "\n",
    "# Load\n",
    "nyc_data = pd.read_csv('../../coronavirus-data/by-boro.csv')\n",
    "\n",
    "# Clean\n",
    "fips = [36005, 36047, 36061, 36081, 36085, 0]\n",
    "state = ['New York', 'New York', ' New York', 'New York', 'New York', 'New York']\n",
    "nyc_data['fips'] = fips\n",
    "nyc_data['state'] = state\n",
    "\n",
    "nyc_data = nyc_data.rename(columns={'CASE_COUNT': 'cases', 'DEATH_COUNT': 'deaths'})\n",
    "\n",
    "# Merge covid_data and nyc_data\n",
    "covid_data = covid_data.merge(nyc_data, how='outer')\n",
    "\n",
    "# Clean\n",
    "covid_ny = covid_data.loc[covid_data['state'] == 'New York']\n",
    "covid_ny = covid_ny.drop(['BOROUGH_GROUP', 'CASE_RATE', 'HOSPITALIZED_RATE', 'DEATH_RATE', 'HOSPITALIZED_COUNT'], axis=1)\n",
    "\n",
    "covid_data = covid_data.drop(['BOROUGH_GROUP', 'CASE_RATE', 'HOSPITALIZED_RATE', 'DEATH_RATE', 'HOSPITALIZED_COUNT'], axis=1)\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, covid_data, left_on='FIPS', right_on='fips')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "(3130, 85)\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Cleaning #\n",
    "############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Cleaning data...')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.rename(columns={'consumer': 'internet_consumer', 'non_consumer': 'internet_nonconsumer', 'all': 'internet_all',\n",
    "                                          'hhs': 'internet_hhs', 'ratio': 'internet_ratio', 'cases': 'covid_cases', 'deaths': 'covid_deaths'})\n",
    "merged_data = merged_data.drop(columns=['date', 'county', 'state', 'fips'])\n",
    "\n",
    "merged_data = merged_data.fillna(0)  # Change NaNs to 0\n",
    "\n",
    "merged_data['internet_percent'] = 100 * merged_data.internet_ratio\n",
    "merged_data['FIPS'] = merged_data['FIPS'].astype(str)\n",
    "\n",
    "merged_data.loc[(merged_data.State == 'Arizona'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'Arizona'), 'FIPS']  # Add the 0s back in to the fips code for first 9 states alphabetically\n",
    "merged_data.loc[(merged_data.State == 'Alabama'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'Alabama'), 'FIPS']\n",
    "merged_data.loc[(merged_data.State == 'Alaska'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'Alaska'), 'FIPS']\n",
    "merged_data.loc[(merged_data.State == 'Arkansas'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'Arkansas'), 'FIPS']\n",
    "merged_data.loc[(merged_data.State == 'California'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'California'), 'FIPS']\n",
    "merged_data.loc[(merged_data.State == 'Colorado'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'Colorado'), 'FIPS']\n",
    "merged_data.loc[(merged_data.State == 'Connecticut'), 'FIPS'] = '0' + merged_data.loc[(merged_data.State == 'Connecticut'), 'FIPS']\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Adults with Obesity...\n",
      "(3130, 85)\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Obesity Data #\n",
    "################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Adults with Obesity...')\n",
    "\n",
    "# Load\n",
    "obesity_data = pd.read_csv('../data/DiabetesAtlasCountyData.csv', skiprows=2, usecols=['County', 'State', 'CountyFIPS', 'Percentage'])\n",
    "\n",
    "# Clean\n",
    "obesity_data['CountyFIPS'] = obesity_data['CountyFIPS'].fillna(0).astype(int)\n",
    "obesity_data['CountyFIPS'] = obesity_data['CountyFIPS'].astype(str)\n",
    "\n",
    "obesity_data.loc[(obesity_data.State == 'Arizona'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'Arizona'),\n",
    "                                                                                           'CountyFIPS']  # Add the 0s back in to the fips code for first 9 states alphabetically\n",
    "obesity_data.loc[(obesity_data.State == 'Alabama'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'Alabama'), 'CountyFIPS']\n",
    "obesity_data.loc[(obesity_data.State == 'Alaska'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'Alaska'), 'CountyFIPS']\n",
    "obesity_data.loc[(obesity_data.State == 'Arkansas'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'Arkansas'), 'CountyFIPS']\n",
    "obesity_data.loc[(obesity_data.State == 'California'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'California'), 'CountyFIPS']\n",
    "obesity_data.loc[(obesity_data.State == 'Colorado'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'Colorado'), 'CountyFIPS']\n",
    "obesity_data.loc[(obesity_data.State == 'Connecticut'), 'CountyFIPS'] = '0' + obesity_data.loc[(obesity_data.State == 'Connecticut'), 'CountyFIPS']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, obesity_data, left_on='FIPS', right_on='CountyFIPS')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.rename(columns={'Percentage': '%  Adults with Obesity', 'State_x': 'State', 'County_x': 'County'})\n",
    "merged_data = merged_data.drop(columns=['% Adults with Obesity', 'County_y', 'State_y', 'CountyFIPS'])\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Heart Disease Death Rate...\n",
      "(3130, 86)\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Heart Disease Data #\n",
    "######################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging Heart Disease Death Rate...')\n",
    "\n",
    "# Load\n",
    "heart_disease = pd.read_csv('../data/all_heart.csv', usecols=['cnty_fips', 'Value', 'display_name'])\n",
    "\n",
    "# Clean\n",
    "heart_disease_split = heart_disease.display_name.str.split(\", \", expand=True)\n",
    "heart_disease_split.columns = ['county', 'state']\n",
    "heart_disease = pd.concat([heart_disease.drop(\"display_name\", axis=1), heart_disease_split], axis=1)\n",
    "\n",
    "heart_disease.state = heart_disease.state.str.replace('[\",(,)]', '')\n",
    "heart_disease.county = heart_disease.county.str.replace('[\",(,)]', '')\n",
    "heart_disease['cnty_fips'] = heart_disease['cnty_fips'].astype(str)\n",
    "\n",
    "heart_disease.loc[(heart_disease.state == 'AZ'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'AZ'), 'cnty_fips']  # Add the 0s back in\n",
    "heart_disease.loc[(heart_disease.state == 'AL'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'AL'), 'cnty_fips']\n",
    "heart_disease.loc[(heart_disease.state == 'AK'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'AK'), 'cnty_fips']\n",
    "heart_disease.loc[(heart_disease.state == 'AR'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'AR'), 'cnty_fips']\n",
    "heart_disease.loc[(heart_disease.state == 'CA'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'CA'), 'cnty_fips']\n",
    "heart_disease.loc[(heart_disease.state == 'CO'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'CO'), 'cnty_fips']\n",
    "heart_disease.loc[(heart_disease.state == 'CT'), 'cnty_fips'] = '0' + heart_disease.loc[(heart_disease.state == 'CT'), 'cnty_fips']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, heart_disease, left_on='FIPS', right_on='cnty_fips')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.rename(columns={'Value': 'Heart Disease Death Rate'})\n",
    "merged_data = merged_data.drop(columns=['cnty_fips', 'county', 'state'])\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Hypertension Death Rate...\n",
      "(3130, 87)\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Hypertension #\n",
    "################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging Hypertension Death Rate...')\n",
    "\n",
    "# Load\n",
    "hypertension = pd.read_csv('../data/hypertension.csv', usecols=['cnty_fips', 'Value', 'display_name'])\n",
    "\n",
    "# Clean\n",
    "hypertension_split = hypertension.display_name.str.split(\", \", expand=True)\n",
    "hypertension_split.columns = ['county', 'state']\n",
    "hypertension = pd.concat([hypertension.drop(\"display_name\", axis=1), hypertension_split], axis=1)\n",
    "\n",
    "hypertension.state = hypertension.state.str.replace('[\",(,)]', '')\n",
    "hypertension.county = hypertension.county.str.replace('[\",(,)]', '')\n",
    "hypertension['cnty_fips'] = hypertension['cnty_fips'].astype(str)\n",
    "\n",
    "hypertension.loc[(hypertension.state == 'AL'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'AL'), 'cnty_fips']  # Add 0s back in\n",
    "hypertension.loc[(hypertension.state == 'AK'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'AK'), 'cnty_fips']\n",
    "hypertension.loc[(hypertension.state == 'AZ'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'AZ'), 'cnty_fips']\n",
    "hypertension.loc[(hypertension.state == 'AR'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'AR'), 'cnty_fips']\n",
    "hypertension.loc[(hypertension.state == 'CA'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'CA'), 'cnty_fips']\n",
    "hypertension.loc[(hypertension.state == 'CO'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'CO'), 'cnty_fips']\n",
    "hypertension.loc[(hypertension.state == 'CT'), 'cnty_fips'] = '0' + hypertension.loc[(hypertension.state == 'CT'), 'cnty_fips']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, hypertension, left_on='FIPS', right_on='cnty_fips')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.rename(columns={'Value': 'Hypertension Death Rate'})\n",
    "merged_data = merged_data.drop(columns=['cnty_fips', 'county', 'state'])\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Load FIPS #\n",
    "#############\n",
    "\n",
    "FIPS_codes = pd.read_csv('../data/FIPS.csv', usecols=['FIPS', 'County', 'State', 'Merge'])\n",
    "FIPS_codes = FIPS_codes.rename(columns={'FIPS': 'FIPS_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Adults 65 and Older...\n",
      "(3129, 87)\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Elderly #\n",
    "###########\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Adults 65 and Older...')\n",
    "\n",
    "# Load\n",
    "pop_elderly = pd.read_csv('../data/elderly_agesex.csv', usecols=['CTYNAME', 'STNAME', 'POPESTIMATE', 'AGE65PLUS_TOT', 'Merge'])\n",
    "\n",
    "# Clean\n",
    "pop_elderly = pd.merge(pop_elderly, FIPS_codes, left_on='Merge', right_on='Merge')  # Merge with FIPS\n",
    "\n",
    "pop_elderly = pop_elderly.drop(columns=['County', 'Merge', 'State'])\n",
    "pop_elderly = pop_elderly.rename(columns={'CTYNAME': 'County_', 'STNAME': 'State_'})\n",
    "pop_elderly['FIPS_'] = pop_elderly['FIPS_'].astype(str)\n",
    "\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'Arizona'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'Arizona'), 'FIPS_']\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'Alabama'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'Alabama'), 'FIPS_']\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'Alaska'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'Alaska'), 'FIPS_']\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'Arkansas'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'Arkansas'), 'FIPS_']\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'California'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'California'), 'FIPS_']\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'Colorado'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'Colorado'), 'FIPS_']\n",
    "pop_elderly.loc[(pop_elderly.State_ == 'Connecticut'), 'FIPS_'] = '0' + pop_elderly.loc[(pop_elderly.State_ == 'Connecticut'), 'FIPS_']\n",
    "\n",
    "pop_elderly['POPESTIMATE'] = pop_elderly['POPESTIMATE'].astype(float)\n",
    "pop_elderly['AGE65PLUS_TOT'] = pop_elderly['AGE65PLUS_TOT'].astype(float)\n",
    "pop_elderly['% Adults 65 and Older'] = (100 * pop_elderly['AGE65PLUS_TOT'] / pop_elderly['POPESTIMATE']).round(decimals=3)\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, pop_elderly, left_on='FIPS', right_on='FIPS_')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.drop(columns=['FIPS_', 'State_', 'County_', 'POPESTIMATE', 'AGE65PLUS_TOT', '% 65 and over'])\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging COPD Mortality Rate...\n",
      "(3129, 88)\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# Mortality #\n",
    "#############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging COPD Mortality Rate...')\n",
    "\n",
    "# Load\n",
    "copd_mortality = pd.read_csv('../data/IHME_USA_COUNTY.csv', usecols=['Location', 'State', 'FIPS', 'Mortality Rate, 2014*'])\n",
    "\n",
    "# Clean\n",
    "copd_mortality = copd_mortality.fillna(0)\n",
    "copd_mortality = copd_mortality.rename(columns={'Mortality Rate, 2014*': 'Mortality'})\n",
    "copd_mortality['FIPS'] = copd_mortality['FIPS'].astype(str)\n",
    "\n",
    "copd_mortality.loc[(copd_mortality.State == 'Arizona'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'Arizona'), 'FIPS']\n",
    "copd_mortality.loc[(copd_mortality.State == 'Alabama'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'Alabama'), 'FIPS']\n",
    "copd_mortality.loc[(copd_mortality.State == 'Alaska'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'Alaska'), 'FIPS']\n",
    "copd_mortality.loc[(copd_mortality.State == 'Arkansas'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'Arkansas'), 'FIPS']\n",
    "copd_mortality.loc[(copd_mortality.State == 'California'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'California'), 'FIPS']\n",
    "copd_mortality.loc[(copd_mortality.State == 'Colorado'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'Colorado'), 'FIPS']\n",
    "copd_mortality.loc[(copd_mortality.State == 'Connecticut'), 'FIPS'] = '0' + copd_mortality.loc[(copd_mortality.State == 'Connecticut'), 'FIPS']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, copd_mortality, left_on='FIPS', right_on='FIPS')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.drop(columns=['Location', 'State_y'])\n",
    "merged_data = merged_data.rename(columns={'State_x': 'State', 'Mortality': 'COPD Mortality Rate'})\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Diagnosed Diabetes...\n",
      "(3129, 88)\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Diabetes #\n",
    "############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Diagnosed Diabetes...')\n",
    "\n",
    "# Load\n",
    "diagnosed_diabetes = pd.read_csv('../data/2017_Diabetes_Diagnosed.csv', skiprows=2, usecols=['County', 'State', 'CountyFIPS', 'Percentage'])\n",
    "\n",
    "# Clean\n",
    "diagnosed_diabetes['CountyFIPS'] = diagnosed_diabetes['CountyFIPS'].fillna(0).astype(int)\n",
    "diagnosed_diabetes['CountyFIPS'] = diagnosed_diabetes['CountyFIPS'].astype(str)\n",
    "\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Arizona'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Arizona'), 'CountyFIPS']\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Alabama'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Alabama'), 'CountyFIPS']\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Alaska'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Alaska'), 'CountyFIPS']\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Arkansas'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Arkansas'), 'CountyFIPS']\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'California'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'California'), 'CountyFIPS']\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Colorado'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Colorado'), 'CountyFIPS']\n",
    "diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Connecticut'), 'CountyFIPS'] = '0' + diagnosed_diabetes.loc[(diagnosed_diabetes.State == 'Connecticut'), 'CountyFIPS']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, diagnosed_diabetes, left_on='FIPS', right_on='CountyFIPS')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.rename(columns={'State_x': 'State', 'County_x': 'County', 'Percentage': '% Diagnosed Diabetes'})\n",
    "merged_data = merged_data.drop(columns=['% Adults with Diabetes', 'County_y', 'State_y', 'CountyFIPS'])\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Nonwhite...\n",
      "(3129, 89)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Race #\n",
    "########\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Nonwhite...')\n",
    "\n",
    "# Load\n",
    "race_acs = pd.read_csv(\"../data/ACSDT5Y2018.B02001_data_with_overlays_2020-10-01T103850.csv\", usecols=[\"GEO_ID\", \"B02001_001E\", \"B02001_002E\"])\n",
    "\n",
    "# Clean\n",
    "race_acs = race_acs.loc[1:race_acs.shape[0]]\n",
    "\n",
    "race_acs.rename(columns={\"GEO_ID\": \"FIPS\", \"B02001_001E\": \"Total\", \"B02001_002E\": \"White_Alone\"}, inplace=True)\n",
    "\n",
    "race_acs[\"FIPS\"] = race_acs[\"FIPS\"].apply(lambda x: x[9:14])\n",
    "race_acs = race_acs.loc[race_acs[\"FIPS\"] != \"\"]\n",
    "\n",
    "race_acs[\"Total\"] = race_acs[\"Total\"].astype(int)\n",
    "race_acs[\"White_Alone\"] = race_acs[\"White_Alone\"].astype(int)\n",
    "\n",
    "race_acs[\"Nonwhite\"] = race_acs[\"Total\"] - race_acs[\"White_Alone\"]\n",
    "race_acs[\"% Nonwhite\"] = 100 * (race_acs[\"Nonwhite\"] / race_acs[\"Total\"])\n",
    "race_acs = race_acs[[\"FIPS\", \"% Nonwhite\"]]\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, race_acs, left_on='FIPS', right_on='FIPS')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % households wo car...\n",
      "(3130, 90)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Cars #\n",
    "########\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % households wo car...')\n",
    "\n",
    "# Load\n",
    "hh_wo_car = pd.read_csv('../data/householdwoutcar_with_fips.csv', usecols=['fips', 'COUNTY_NAME', 'STATE_NAME', 'Number_Households_Wout_Car'],  dtype={'fips': str})\n",
    "\n",
    "# Clean\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Arizona'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Arizona'), 'fips']\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Alabama'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Alabama'), 'fips']\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Alaska'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Alaska'), 'fips']\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Arkansas'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Arkansas'), 'fips']\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'California'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'California'), 'fips']\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Colorado'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Colorado'), 'fips']\n",
    "hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Connecticut'), 'fips'] = '0' + hh_wo_car.loc[(hh_wo_car.STATE_NAME == 'Connecticut'), 'fips']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, hh_wo_car, left_on=['FIPS'], right_on=['fips'])\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.rename(columns={'Number_Households_Wout_Car': 'hh_wo_car'})\n",
    "merged_data = merged_data.drop(['fips', 'COUNTY_NAME', 'STATE_NAME'], axis=1)\n",
    "\n",
    "merged_data['% households wo car'] = merged_data['hh_wo_car'] / (merged_data['internet_hhs'] * 1000)\n",
    "merged_data = merged_data.drop('hh_wo_car', axis=1)\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Number of Hospitals...\n",
      "(3132, 91)\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# Hospitals #\n",
    "#############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging Number of Hospitals...')\n",
    "\n",
    "# Load\n",
    "hospitals = pd.read_csv('../data/Hospitals.csv', usecols=['ID', 'STATE', 'COUNTYFIPS'])\n",
    "\n",
    "# Clean\n",
    "hospitals_grouped = hospitals.groupby(['STATE', 'COUNTYFIPS'], as_index=False).count().rename(columns={'ID': 'Number of Hospitals'})\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, hospitals_grouped, left_on='FIPS', right_on='COUNTYFIPS', how='left')  # Note: using how=left to account for missing values (counties with no hospitals)\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.drop(['STATE', 'COUNTYFIPS'], axis=1)\n",
    "merged_data['Number of Hospitals'] = merged_data['Number of Hospitals'].fillna(0)  # Fill in the null hospital rows with 0\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % disabled...\n",
      "(3132, 92)\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Disability #\n",
    "##############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % disabled...')\n",
    "\n",
    "# Load\n",
    "col_name = 'Estimate!!Percent with a disability!!Subject!!Total civilian noninstitutionalized population'\n",
    "disability = pd.read_csv('../data/disability_data.csv', skiprows=1, usecols=['id', 'Geographic Area Name', col_name])\n",
    "\n",
    "# Clean\n",
    "disability = disability.rename(columns={col_name: '% disabled', 'Geographic Area Name': 'Location'})\n",
    "\n",
    "fips = []  # Add the fips codes\n",
    "for county_id in disability['id']:\n",
    "    fips_i = county_id[-5:]\n",
    "    fips.append(fips_i)\n",
    "\n",
    "disability['FIPS'] = fips\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, disability, left_on=['FIPS'], right_on=['FIPS'])\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.drop(['id', 'Location'], axis=1)\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Without Health Insurance...\n",
      "(3132, 93)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Health Insurance #\n",
    "####################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Without Health Insurance...')\n",
    "\n",
    "# Load\n",
    "health_insr = pd.read_csv(\"../data/sahie_2018.csv\", low_memory=False)\n",
    "\n",
    "# Clean\n",
    "health_insr[\"FIPS\"] = health_insr[\"statefips\"].astype(str).apply(lambda x: x if len(x) > 1 else \"0\" * (2 - len(str(x))) + str(x) ) + \\\n",
    "    health_insr[\"countyfips\"].astype(str).apply(lambda x: x if len(str(x)) > 2 else \"0\" * (3 - len(str(x))) + str(x))\n",
    "\n",
    "health_insr_subset = health_insr.loc[(health_insr[\"agecat\"] == 0) &\n",
    "                                     (health_insr[\"racecat\"] == 0) &\n",
    "                                     (health_insr[\"sexcat\"] == 0) &\n",
    "                                     (health_insr[\"iprcat\"] == 0) &\n",
    "                                     (health_insr[\"countyfips\"] != 0)]\n",
    "\n",
    "health_insr_subset = health_insr_subset[[\"FIPS\", \"PCTUI\"]]\n",
    "health_insr_subset[\"PCTUI\"] = health_insr_subset[\"PCTUI\"].apply(pd.to_numeric, errors=\"coerce\")\n",
    "health_insr_subset = health_insr_subset.loc[health_insr_subset[\"PCTUI\"].isnull() == False]\n",
    "health_insr_subset.rename(columns={\"PCTUI\": \"% Without Health Insurance\"}, inplace=True)\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, health_insr_subset, left_on='FIPS', right_on='FIPS')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Limited English Proficiency...\n",
      "(3132, 94)\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Limited English #\n",
    "###################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Limited English Proficiency...')\n",
    "\n",
    "# Load\n",
    "limited_eng = pd.read_csv(\"../data/ACSST5Y2018.S1602_data_with_overlays.csv\", usecols=[\"GEO_ID\", \"S1602_C01_001E\", \"S1602_C03_001E\"])\n",
    "limited_eng = limited_eng.loc[1:limited_eng.shape[0]]\n",
    "\n",
    "# Clean\n",
    "limited_eng.rename(columns={\"GEO_ID\": \"FIPS\", \"S1602_C01_001E\": \"Total_Households\", \"S1602_C03_001E\": \"Number_Limited_English_Speaking\"}, inplace=True)\n",
    "\n",
    "limited_eng[\"FIPS\"] = limited_eng[\"FIPS\"].apply(lambda x: x[9:14])\n",
    "limited_eng = limited_eng.loc[limited_eng[\"FIPS\"] != \"\"]\n",
    "\n",
    "limited_eng[\"Total_Households\"] = limited_eng[\"Total_Households\"].astype(int)\n",
    "limited_eng[\"Number_Limited_English_Speaking\"] = limited_eng[\"Number_Limited_English_Speaking\"].astype(int)\n",
    "limited_eng[\"% Limited English Proficiency\"] = 100 * (limited_eng[\"Number_Limited_English_Speaking\"] / limited_eng[\"Total_Households\"])\n",
    "\n",
    "limited_eng = limited_eng[[\"FIPS\", \"% Limited English Proficiency\"]]\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, limited_eng, left_on='FIPS', right_on='FIPS')\n",
    "merged_data[\"% Limited English Proficiency\"].isnull().sum() / merged_data.shape[0]  # Reviewing the percent of missing data in the merged column\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % workers commuting by public transit...\n",
      "(3132, 95)\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Public Transit #\n",
    "##################\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % workers commuting by public transit...')\n",
    "\n",
    "# Load\n",
    "public_transit = pd.read_csv('../data/ACS_S0801_Commute.csv', low_memory=False, usecols=['State', 'County', 'Merge',\n",
    "                                                                                         'Estimate!!Total!!Workers 16 years and over!!MEANS OF TRANSPORTATION TO WORK!!Public transportation (excluding taxicab)'])\n",
    "\n",
    "# Clean\n",
    "public_transit = pd.merge(public_transit, FIPS_codes, left_on='Merge', right_on='Merge')\n",
    "\n",
    "public_transit = public_transit.drop(columns=['County_y', 'Merge', 'State_y'])\n",
    "public_transit = public_transit.rename(columns={'County_x': 'County', 'State_x': 'State',\n",
    "                                                'Estimate!!Total!!Workers 16 years and over!!MEANS OF TRANSPORTATION TO WORK!!Public transportation (excluding taxicab)': '% workers commuting by public transit'})\n",
    "public_transit['FIPS_'] = public_transit['FIPS_'].astype(str)\n",
    "\n",
    "public_transit.loc[(public_transit.State == 'Arizona'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'Arizona'), 'FIPS_']\n",
    "public_transit.loc[(public_transit.State == 'Alabama'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'Alabama'), 'FIPS_']\n",
    "public_transit.loc[(public_transit.State == 'Alaska'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'Alaska'), 'FIPS_']\n",
    "public_transit.loc[(public_transit.State == 'Arkansas'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'Arkansas'), 'FIPS_']\n",
    "public_transit.loc[(public_transit.State == 'California'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'California'), 'FIPS_']\n",
    "public_transit.loc[(public_transit.State == 'Colorado'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'Colorado'), 'FIPS_']\n",
    "public_transit.loc[(public_transit.State == 'Connecticut'), 'FIPS_'] = '0' + public_transit.loc[(public_transit.State == 'Connecticut'), 'FIPS_']\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, public_transit, left_on='FIPS', right_on='FIPS_')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.drop(columns=['County_y', 'FIPS_', 'State_y'])\n",
    "merged_data = merged_data.rename(columns={'County_x': 'County', 'State_x': 'State'})\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging % Veterans in Civilian Adult Population...\n",
      "(3132, 96)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# Vets #\n",
    "########\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging % Veterans in Civilian Adult Population...')\n",
    "\n",
    "# Load\n",
    "est_vets_percent = pd.read_csv('../data/veteran_percent_est.csv', dtype={'FIPS': object}, index_col=0)\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, est_vets_percent, on='FIPS')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging opioid death rate...\n",
      "(3132, 100)\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Opioids #\n",
    "###########\n",
    "\n",
    "if PRINTING:\n",
    "    print('Merging opioid death rate...')\n",
    "\n",
    "# Load\n",
    "opioids = pd.read_csv('../data/opioid_deaths_2018.txt', delimiter='\\t', usecols=['County Code', 'Deaths', 'Population', ], dtype={'County Code': object})\n",
    "\n",
    "# Clean\n",
    "opioids = opioids[opioids['Population'] != 'Missing']\n",
    "\n",
    "opioids[\"Deaths\"] = opioids[\"Deaths\"].replace({'Suppressed': 5})  # Replace the suppressed data with 5 (data is suppressed when there are <10 deaths in the county)\n",
    "opioids['Deaths'] = pd.to_numeric(opioids['Deaths'])\n",
    "opioids['Population'] = pd.to_numeric(opioids['Population'])\n",
    "\n",
    "opioids.fillna(0)\n",
    "opioids['opioid death rate'] = opioids['Deaths'] / (opioids['Population'] / 100000)  # Calculate death rate\n",
    "\n",
    "# Merge\n",
    "merged_data = pd.merge(merged_data, opioids, left_on='FIPS', right_on='County Code')\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to merged_data_script.csv...\n",
      "(3132, 96)\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Write Data #\n",
    "##############\n",
    "\n",
    "if PRINTING:\n",
    "    print('Writing data to merged_data_script.csv...')\n",
    "\n",
    "# Clean\n",
    "merged_data = merged_data.drop(columns='% Uninsured')\n",
    "merged_data = merged_data.drop(columns=['County Code', 'Deaths_y', 'Population_y'])\n",
    "merged_data = merged_data.rename(columns={'Deaths_x': 'Deaths', 'Population_x': 'Population'})\n",
    "\n",
    "merged_data.head()\n",
    "\n",
    "print(merged_data.shape)\n",
    "\n",
    "# Write\n",
    "merged_data.to_csv('../data/merged_data_script.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good!\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Compare Script and Notebook #\n",
    "###############################\n",
    "\n",
    "data_nb = pd.read_csv('../data/merged_data.csv')\n",
    "data_s = pd.read_csv('../data/merged_data_script.csv')\n",
    "\n",
    "if data_nb.equals(data_s):\n",
    "    print('All good!') \n",
    "elif data_nb.shape != data_s.shape:\n",
    "    print('Shapes are different.')\n",
    "elif np.any(data_nb.columns != data_s.columns):\n",
    "    print('Column names are different.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
